
# Implementation Plan: Unified Raindrop Export CLI

**Branch**: `001-build-a-small` | **Date**: 2025-10-03 | **Spec**: `/specs/001-build-a-small/spec.md`
**Input**: Feature specification from `/specs/001-build-a-small/spec.md`

## Execution Flow (/plan command scope)
```
1. Load feature spec from Input path
   → If not found: ERROR "No feature spec at {path}"
2. Fill Technical Context (scan for NEEDS CLARIFICATION)
   → Detect Project Type from file system structure or context (web=frontend+backend, mobile=app+api)
   → Set Structure Decision based on project type
3. Fill the Constitution Check section based on `.specify/memory/constitution.md`.
4. Evaluate Constitution Check section below
   → If violations exist: Document in Complexity Tracking
   → If no justification possible: ERROR "Simplify approach first"
   → Update Progress Tracking: Initial Constitution Check
5. Execute Phase 0 → research.md
   → If NEEDS CLARIFICATION remain: ERROR "Resolve unknowns"
6. Execute Phase 1 → contracts, data-model.md, quickstart.md, agent-specific template file (e.g., `CLAUDE.md` for Claude Code, `.github/copilot-instructions.md` for GitHub Copilot, `GEMINI.md` for Gemini CLI, `QWEN.md` for Qwen Code or `AGENTS.md` for opencode).
7. Re-evaluate Constitution Check section
   → If new violations: Refactor design, return to Phase 1
   → Update Progress Tracking: Post-Design Constitution Check
8. Plan Phase 2 → Describe task generation approach (DO NOT create tasks.md)
9. STOP - Ready for /tasks command
```

**IMPORTANT**: The /plan command STOPS at step 7. Phases 2-4 are executed by other commands:
- Phase 2: /tasks command creates tasks.md
- Phase 3-4: Implementation execution (manual or via tools)

## Summary
Deliver a command-line tool that authenticates to Raindrop using a token stored in `.env`, retrieves every collection and their active raindrops despite pagination or throttling, and prints the aggregated dataset as a JSON array with key metadata for each item.

## Technical Context
**Language/Version**: Python 3.13 (per `pyproject.toml` / uv defaults)  
**Primary Dependencies**: Gracy (HTTP client), httpx (indirect via Gracy), Click (CLI), Rich (console rendering), python-dotenv or uv-managed dotenv support (verify)  
**Storage**: N/A (remote Raindrop API only)  
**Testing**: pytest with pytest-httpx or respx for HTTP mocking; use built-in asyncio test utilities  
**Target Platform**: Cross-platform CLI (macOS/Linux/Windows) running in terminal  
**Project Type**: Single Python package (`src/raindrop_enhancer`)  
**Performance Goals**: Adhere to constitution default for batch operations (≤60s for 10k raindrops) and p95 latency <200ms per API request pipeline under normal conditions  
**Constraints**: Must respect Raindrop rate limits (120 req/min) with exponential backoff; memory footprint ≤150MB; no persistent storage  
**Scale/Scope**: Single-user execution exporting personal library; expect up to 10k raindrops across tens of collections

## Constitution Check
*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

- **Code Quality**: Enforce Black/Ruff via uv tasks; implement Gracy client and CLI modules with full type hints, dataclasses for models, and docstrings on exported functions. Keep functions below complexity threshold by decomposing pagination and retry into helpers.
- **Testing Standards & TDD**: Plan contract tests for Raindrop endpoints using mocked HTTP responses, unit tests for pagination/retry logic, and integration tests invoking Click CLI via `CliRunner`. Write failing tests first, ensure deterministic behavior with recorded fixtures and no real network calls. Maintain coverage ≥90% on touched code.
- **UX Consistency**: CLI command `raindrop-export` will expose `--json` (default JSON output), `--quiet/--verbose` toggles leveraging Rich for progress, `--dry-run` to validate connectivity without exporting, and `--help` auto-generated by Click. Errors go to stderr with distinct exit codes.
- **Performance & Efficiency**: Set target to export 10k items ≤60s by batching API calls with pagination size awareness, reuse HTTP session, and honor backoff to avoid request storms. Add benchmark hook in quickstart to time sample run and document profiling approach if thresholds challenged.
- **Tooling & Dependency Management**: All commands executed via `uv run`; dependencies managed with `uv add` (ensure Click/Rich already pinned). Update documentation to note uv usage where relevant and ensure lockfile regenerated after dependency changes.

**Initial Constitution Check Status**: PASS with planned mitigations (no violations requiring Complexity Tracking).

**Post-Design Constitution Check**: Research and design artifacts confirm ability to satisfy gates—data model enforces typed entities, contract tests planned for API interactions, CLI flags enumerate UX expectations, performance benchmark documented in quickstart, and uv-based workflows captured. Status: PASS.

## Project Structure

### Documentation (this feature)
```
specs/[###-feature]/
├── plan.md              # This file (/plan command output)
├── research.md          # Phase 0 output (/plan command)
├── data-model.md        # Phase 1 output (/plan command)
├── quickstart.md        # Phase 1 output (/plan command)
├── contracts/           # Phase 1 output (/plan command)
└── tasks.md             # Phase 2 output (/tasks command - NOT created by /plan)
```

### Source Code (repository root)
```
src/
└── raindrop_enhancer/
      ├── __init__.py
      ├── cli.py                  # Click entrypoint integrating Rich output and JSON serialization
      ├── api/
      │   ├── __init__.py
      │   └── raindrop_client.py  # Gracy-based client handling auth, pagination, retries
      ├── models.py               # Dataclasses / TypedDicts for collections and raindrops
      └── exporters/
            ├── __init__.py
            └── json_exporter.py    # Transforms domain objects into JSON array output

tests/
├── contract/
│   ├── __init__.py
│   └── test_raindrop_endpoints.py   # Validates request/response schema against mocked API
├── integration/
│   ├── __init__.py
│   └── test_cli_export.py      # Exercises Click CLI end-to-end with mocked client
└── unit/
      ├── __init__.py
      ├── test_raindrop_client.py # Tests pagination, retry, filtering logic
      └── test_json_exporter.py   # Ensures JSON formatting adherence
```

**Structure Decision**: Single-package CLI project under `src/raindrop_enhancer` with layered modules (API client → exporter → CLI) and mirrored test suites under `tests/` segmented by contract/unit/integration per constitution.

## Phase 0: Outline & Research
1. **Research focus areas**
   - Confirm Raindrop API endpoints and pagination mechanics for collections and raindrops (GET `/collections` and `/raindrops/:collectionId` parameters).
   - Determine authentication workflow using existing test token with bearer header and `.env` loading strategy (verify python-dotenv usage under uv).
   - Identify Gracy configuration patterns for retries, throttling, and pagination suitable for rate-limited APIs.
   - Review Click + Rich patterns for CLI output with optional JSON serialization and progress feedback.

2. **Research tasks dispatched**
   - Task: "Research Raindrop API collection & raindrop listing endpoints and pagination constraints for CLI exporter"
   - Task: "Find best practices for configuring Gracy retries/throttling for rate-limited REST APIs"
   - Task: "Review Click and Rich integration patterns for JSON-output-first CLIs with verbosity flags"
   - Task: "Verify dotenv loading approach with uv-managed projects (python-dotenv vs. built-in)"

3. **Consolidation plan**
   - Document findings in `research.md` with Decision/Rationale/Alternatives for each area.
   - Record pagination parameters (page size, continuation fields) and retry backoff strategy (initial delay, cap) explicitly.
   - Capture CLI flag mapping and JSON structure contract to feed Phase 1 design.

**Output**: research.md capturing endpoint usage, Gracy config, CLI output strategy, and env loading approach.

## Phase 1: Design & Contracts
*Prerequisites: research.md complete*

1. **Data modeling**
   - Define `Collection` and `Raindrop` dataclasses/TypedDicts including identifiers, titles, URLs, timestamps, tags, and origin collection info.
   - Capture pagination cursors or page indices used in responses, plus metadata for total counts to drive loops.

2. **API contracts**
   - Document expected HTTP interactions for `GET /collections` and `GET /raindrops/:collectionId` including query params (`page`, `perpage`, `sort`, `search`, `collectionId=0` for ungrouped).
   - Generate OpenAPI-like contract in `/contracts/raindrop_exporter.yaml` summarizing request headers (Authorization bearer) and response schemas highlighting fields consumed (active status, tags, created, lastUpdate).

3. **Contract tests**
   - Under `tests/contract/test_raindrop_endpoints.py`, create failing tests asserting the Gracy client hits the correct endpoints with headers and handles pagination/responses according to contract.

4. **Integration & unit test scaffolding**
   - Map user story to `tests/integration/test_cli_export.py` verifying CLI invocation outputs JSON array and handles missing token scenario.
   - Unit tests for pagination/resiliency (retry on 429) and JSON exporter formatting.

5. **Quickstart**
   - Provide instructions in `quickstart.md` for setting up `.env`, running `uv run raindrop-export`, and executing tests/documentation commands.

6. **Agent context**
   - Run `.specify/scripts/bash/update-agent-context.sh codex` after drafting design docs to register new libraries (Click, Rich, Gracy usage details).

**Output**: data-model.md, contracts/raindrop_exporter.yaml, quickstart.md, failing tests skeletons, updated agent context file.

## Phase 2: Task Planning Approach
*This section describes what the /tasks command will do - DO NOT execute during /plan*

**Task Generation Strategy**:
- Load `.specify/templates/tasks-template.md` as base
- Derive tasks from research + design artifacts (contracts, data-model, quickstart)
- Map each Gracy contract to contract test tasks [P]
- Map each entity/module to implementation tasks preceded by failing tests
- Include CLI UX validation tasks (Click options, Rich output) before wiring implementation

**Ordering Strategy**:
- Enforce TDD: write contract/unit/integration tests prior to implementation of corresponding modules
- Sequence: data models → Gracy client → exporter → CLI → documentation updates
- Mark independent tasks (e.g., unit tests for exporter vs CLI) as [P] for potential parallelization

**Estimated Output**: 18-22 ordered tasks in tasks.md (lean feature scope)

**IMPORTANT**: This phase is executed by the /tasks command, NOT by /plan

## Phase 3+: Future Implementation
*These phases are beyond the scope of the /plan command*

**Phase 3**: Task execution (/tasks command creates tasks.md)  
**Phase 4**: Implementation (execute tasks.md following constitutional principles)  
**Phase 5**: Validation (run tests, execute quickstart.md, performance validation)

## Complexity Tracking
*Fill ONLY if Constitution Check has violations that must be justified*

| Violation | Why Needed | Simpler Alternative Rejected Because |
|-----------|------------|-------------------------------------|
| [e.g., 4th project] | [current need] | [why 3 projects insufficient] |
| [e.g., Repository pattern] | [specific problem] | [why direct DB access insufficient] |


## Progress Tracking
*This checklist is updated during execution flow*

**Phase Status**:
- [x] Phase 0: Research complete (/plan command)
- [x] Phase 1: Design complete (/plan command)
- [ ] Phase 2: Task planning complete (/plan command - describe approach only)
- [ ] Phase 3: Tasks generated (/tasks command)
- [ ] Phase 4: Implementation complete
- [ ] Phase 5: Validation passed

**Gate Status**:
- [x] Initial Constitution Check: PASS
- [x] Post-Design Constitution Check: PASS
- [x] All NEEDS CLARIFICATION resolved
- [ ] Complexity deviations documented

---
*Based on Constitution v1.0.0 - See `.specify/memory/constitution.md`*
